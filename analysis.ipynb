{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import NaN\n",
    "from itertools import chain\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напрямую с файлами\n",
    "ac = pd.read_csv('results/raw/1С-аналитик.csv', sep=';', encoding='utf-8')\n",
    "ds = pd.read_csv('results/raw/Data Scientist.csv', sep=';', encoding='utf-8')\n",
    "do = pd.read_csv('results/raw/DataOps-инженер.csv', sep=';', encoding='utf-8')\n",
    "ab = pd.read_csv('results/raw/Аналитик BI.csv', sep=';', encoding='utf-8')\n",
    "ad = pd.read_csv('results/raw/Аналитик данных.csv', sep=';', encoding='utf-8')\n",
    "dj = pd.read_csv('results/raw/Дата-журналист.csv', sep=';', encoding='utf-8')\n",
    "de = pd.read_csv('results/raw/Дата-инженер.csv', sep=';', encoding='utf-8')\n",
    "ma = pd.read_csv('results/raw/Маркетинговый аналитик.csv', sep=';', encoding='utf-8')\n",
    "pa = pd.read_csv('results/raw/Продуктовый аналитик.csv', sep=';', encoding='utf-8')\n",
    "sa = pd.read_csv('results/raw/Системный аналитик.csv', sep=';', encoding='utf-8')\n",
    "fa = pd.read_csv('results/raw/Финансовый аналитик.csv', sep=';', encoding='utf-8')\n",
    "ba = pd.read_csv('results/raw/Бизнес-аналитик.csv', sep=';', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавление меток широта-долгота\n",
    "with open('geo_rus.json', encoding='utf-8') as geo:\n",
    "    cities = json.load(geo)\n",
    "\n",
    "def lat(row):\n",
    "    for el in cities:\n",
    "        if row == el['city']:\n",
    "            return float(el['lat'])\n",
    "        \n",
    "def lon(row):\n",
    "    for el in cities:\n",
    "        if row == el['city']:\n",
    "            return float(el['lon'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.concat([ds, do, ab, ad, dj, de, ma, sa, ac, fa, ba, pa])\n",
    "\n",
    "full['lat'] = full['city'].apply(lat)\n",
    "full['lon'] = full['city'].apply(lon)\n",
    "full = full[['id', 'spec', 'job_title', 'city', 'lat', 'lon', \n",
    "         'employer', 'schedule', 'skills', 'experience', \n",
    "         'published', 'salary_from', 'salary_to', 'currency']]\n",
    "\n",
    "full.to_csv('vacancies.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_sk = ['1c|1с', 'agile|scrum|kanban', 'управление', 'erp', 'отчет',\n",
    "         'анализ', 'тз', 'srs', 'моделирование', 'bpmn', 'тестирование',\n",
    "         'документ']\n",
    "\n",
    "ds_sk = ['анализ', 'sheets', 'статистика', 'data studio', 'python', 'sql',\n",
    "         'ml', 'machine learning', 'сбор', 'визуализация', 'исследование',\n",
    "         'нейронные сети', 'нейросети', 'временные ряды', 'алгоритм',\n",
    "         'sklearn', 'tensorflow', 'pytorch','cv', 'gan', 'nlp']\n",
    "\n",
    "de_do_sk = ['sql', 'базы данных', 'etl', 'power bi|powerbi', 'python', \n",
    "            'pandas', 'numpy', 'hadoop', 'mapreduce', 'apache', 'kafka', \n",
    "            'spark', 'airflow', 'clickhouse', 'yandex cloud', 'docker', \n",
    "            'kubernetes', 'ansible', 'gitlab ci', 'mlflow']\n",
    "\n",
    "ab_sk = ['анализ', 'sheets', 'excel', 'статистика', 'визуализация', \n",
    "         'data studio', 'power bi|powerbi', 'pivot', 'datalens', 'tableau',\n",
    "         'сбор', 'sql', 'ssas']\n",
    "\n",
    "ad_sk = ['анализ', 'sheets', 'excel', 'статистика', 'визуализация',\n",
    "         'data studio', 'python', 'jupyter notebook', 'numpy', \n",
    "         'pandas', 'сбор', 'sql', 'ml', 'machine learning', 'hadoop']\n",
    "\n",
    "dj_sk = ['анализ', 'сбор', 'очистка', 'визуализация', 'построение карт', 'сторителлинг',\n",
    "         'python', 'pandas', 'статистика', 'tableau']\n",
    "\n",
    "ma_sk = ['анализ', 'sheets', 'статистика', 'визуализация', 'google looker studio',\n",
    "         'метрики', 'юнит-экономика', 'поиск точек роста', 'RFM-анализ', \n",
    "         'когортный анализ', 'веб-аналитика', 'яндекс метрика', 'google analitics',\n",
    "         'ab', 'sql', 'power bi|powerbi', 'python', 'numpy', 'pandas', 'api']\n",
    "\n",
    "pa_sk = ['анализ', 'юнит-экономика', 'ab', 'sql', 'tableau', 'power bi|powerbi', \n",
    "         'python', 'numpy', 'pandas', 'исследов']\n",
    "\n",
    "sa_sk = ['разработка по', 'agile', 'scrum', 'моделирование бизнес-процессов',\n",
    "         'нотации', 'проектирование', 'сбор', 'описание', 'визуализация',\n",
    "         'прототипирование', 'figma', 'sql', 'rest api', 'soap', 'open api',\n",
    "         'проектная документация', 'cjm', 'тз', 'спецификация', 'SRS', 'bcm']\n",
    "\n",
    "fa_sk = ['1с', 'бухгалтер', 'финансовая', 'анализ', 'управление', 'статистика', \n",
    "         'план-фактный анализ', 'планирование', 'моделирование', 'презентац',\n",
    "         'powerpoint', 'excel', 'визуализация']\n",
    "\n",
    "ba_sk = ['моделирование', 'анализ', 'оптимизация', 'отчетност', 'сбор',\n",
    "         'tableau', 'bi', 'исследовани', 'agile|scrum|kanban', 'тз', 'документ']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топ навыков"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 / 12 Аналитик данных, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "ad.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = ad.skills.str.split(',').map(len)\n",
    "\n",
    "ad = pd.DataFrame({'id': np.repeat(ad['id'], lens),\n",
    "                    'spec': np.repeat(ad['spec'], lens),\n",
    "                    'experience': np.repeat(ad['experience'], lens),\n",
    "                    'skills': chainer(ad['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = ad.loc[ad.skills.str.contains('|'.join(ad_sk))]\n",
    "ad.skills = ad.skills.str.strip()\n",
    "\n",
    "ad.loc[(ad.skills.str.contains('sql'), 'skills')] = 'sql'\n",
    "ad.loc[(ad.skills.str.contains('excel'), 'skills')] = 'excel'\n",
    "ad.loc[(ad.skills.str.contains('machine learning'), 'skills')] = 'ml'\n",
    "ad.loc[(ad.skills.str.contains('анализ'), 'skills')] = 'анализ (данных, финансовый, т.д.)'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 / 12 Data Scientist, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.drop(['job_title', 'city', 'employer', 'schedule', \n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "ds.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = ds.skills.str.split(',').map(len)\n",
    "\n",
    "ds = pd.DataFrame({'id': np.repeat(ds['id'], lens),\n",
    "                    'spec': np.repeat(ds['spec'], lens),\n",
    "                    'experience': np.repeat(ds['experience'], lens),\n",
    "                    'skills': chainer(ds['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.loc[ds.skills.str.contains('|'.join(ds_sk))]\n",
    "ds.skills = ds.skills.str.strip()\n",
    "\n",
    "ds.loc[(ds.skills.str.contains('sql'), 'skills')] = 'sql'\n",
    "ds.loc[(ds.skills.str.contains('excel'), 'skills')] = 'excel'\n",
    "ds.loc[(ds.skills.str.contains('machine learning'), 'skills')] = 'ml'\n",
    "ds.loc[(ds.skills.str.contains('ml'), 'skills')] = 'ml'\n",
    "ds.loc[(ds.skills.str.contains('анализ'), 'skills')] = 'анализ (данных, финансовый, т.д.)'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 / 12 Аналитик BI, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab.drop(['job_title', 'city', 'employer', 'schedule', \n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "ab.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = ab.skills.str.split(',').map(len)\n",
    "\n",
    "ab = pd.DataFrame({'id': np.repeat(ab['id'], lens),\n",
    "                    'spec': np.repeat(ab['spec'], lens),\n",
    "                    'experience': np.repeat(ab['experience'], lens),\n",
    "                    'skills': chainer(ab['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = ab.loc[ab.skills.str.contains('|'.join(ab_sk))]\n",
    "ab.skills = ab.skills.str.strip()\n",
    "\n",
    "ab.loc[(ab.skills.str.contains('sql'), 'skills')] = 'sql'\n",
    "ab.loc[(ab.skills.str.contains('excel'), 'skills')] = 'excel'\n",
    "ab.loc[(ab.skills.str.contains('bi'), 'skills')] = 'power bi'\n",
    "ab.loc[(ab.skills.str.contains('pivot'), 'skills')] = 'pivot'\n",
    "ab.loc[(ab.skills.str.contains('анализ'), 'skills')] = 'анализ (данных, финансовый, т.д.)'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 / 12 Системный аналитик, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "sa.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = sa.skills.str.split(',').map(len)\n",
    "\n",
    "sa = pd.DataFrame({'id': np.repeat(sa['id'], lens),\n",
    "                    'spec': np.repeat(sa['spec'], lens),\n",
    "                    'experience': np.repeat(sa['experience'], lens),\n",
    "                    'skills': chainer(sa['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = sa.loc[sa.skills.str.contains('|'.join(sa_sk))]\n",
    "sa.skills = sa.skills.str.strip()\n",
    "\n",
    "sa.loc[(sa.skills.str.contains('sql'), 'skills')] = 'sql'\n",
    "sa.loc[(sa.skills.str.contains('agile'), 'skills')] = 'agile'\n",
    "sa.loc[(sa.skills.str.contains('тз'), 'skills')] = 'написание тз'\n",
    "sa.loc[(sa.skills.str.contains('soap'), 'skills')] = 'soap'\n",
    "sa.loc[(sa.skills.str.contains('моделирование | проектирование'), 'skills')] = 'проектирование (интерфейсов, api, т.д.)'\n",
    "sa.loc[(sa.skills.str.contains('сбор требований'), 'skills')] = 'сбор требований'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 / 12 Маркетинговый аналитик, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "ma.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = ma.skills.str.split(',').map(len)\n",
    "\n",
    "ma = pd.DataFrame({'id': np.repeat(ma['id'], lens),\n",
    "                    'spec': np.repeat(ma['spec'], lens),\n",
    "                    'experience': np.repeat(ma['experience'], lens),\n",
    "                    'skills': chainer(ma['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = ma.loc[ma.skills.str.contains('|'.join(ma_sk))]\n",
    "ma.skills = ma.skills.str.strip()\n",
    "\n",
    "ma.loc[(ma.skills.str.contains('анализ'), 'skills')] = 'анализ (данных, финансовый, т.д.)'\n",
    "ma.loc[(ma.skills.str.contains('sql'), 'skills')] = 'sql'\n",
    "ma.loc[(ma.skills.str.contains('статистика'), 'skills')] = 'статистика'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 / 12 Дата-журналист, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "dj.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = dj.skills.str.split(',').map(len)\n",
    "\n",
    "dj = pd.DataFrame({'id': np.repeat(dj['id'], lens),\n",
    "                    'spec': np.repeat(dj['spec'], lens),\n",
    "                    'experience': np.repeat(dj['experience'], lens),\n",
    "                    'skills': chainer(dj['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj = dj.loc[dj.skills.str.contains('|'.join(dj_sk))]\n",
    "dj.skills = dj.skills.str.strip()\n",
    "\n",
    "dj.loc[(dj.skills.str.contains('анализ'), 'skills')] = 'анализ (данных, финансовый, т.д.)'\n",
    "dj.loc[(dj.skills.str.contains('сбор'), 'skills')] = 'сбор данных'\n",
    "dj.loc[(dj.skills.str.contains('визуализация'), 'skills')] = 'визуализация данных'\n",
    "dj.loc[(dj.skills.str.contains('storytelling'), 'skills')] = 'сторителлинг'\n",
    "dj.loc[(dj.skills.str.contains('story telling'), 'skills')] = 'сторителлинг'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7-8 / 12 Дата-инженер | DataOps-инженер, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataOps\n",
    "do.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "do.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = do.skills.str.split(',').map(len)\n",
    "\n",
    "do = pd.DataFrame({'id': np.repeat(do['id'], lens),\n",
    "                    'spec': np.repeat(do['spec'], lens),\n",
    "                    'experience': np.repeat(do['experience'], lens),\n",
    "                    'skills': chainer(do['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['python', 'docker', 'clickhouse', 'airflow', 'kubernetes', 'kafka',\n",
       "       'nosql', 'hadoop'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do = do.loc[do.skills.str.contains('|'.join(de_do_sk))]\n",
    "do.skills = do.skills.str.strip()\n",
    "\n",
    "do.skills.unique()\n",
    "\n",
    "# do.skills.loc[(do.skills.str.contains('...'))] = '...'\n",
    "# do.skills.loc[(do.skills.str.contains('...'))] = '...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дата-инженер\n",
    "de.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "de.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = de.skills.str.split(',').map(len)\n",
    "\n",
    "de = pd.DataFrame({'id': np.repeat(de['id'], lens),\n",
    "                    'spec': np.repeat(de['spec'], lens),\n",
    "                    'experience': np.repeat(de['experience'], lens),\n",
    "                    'skills': chainer(de['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = de.loc[de.skills.str.contains('|'.join(de_do_sk))]\n",
    "de.skills = de.skills.str.strip()\n",
    "\n",
    "de.loc[(de.skills.str.contains('sql'), 'skills')] = 'sql'\n",
    "de.loc[(de.skills.str.contains('bi'), 'skills')] = 'power bi'\n",
    "de.loc[(de.skills.str.contains('airflow'), 'skills')] = 'airflow'\n",
    "de.loc[(de.skills.str.contains('nifi|ni-fi'), 'skills')] = 'nifi'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 / 12 Финансовый аналитик, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "fa.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = fa.skills.str.split(',').map(len)\n",
    "\n",
    "fa = pd.DataFrame({'id': np.repeat(fa['id'], lens),\n",
    "                    'spec': np.repeat(fa['spec'], lens),\n",
    "                    'experience': np.repeat(fa['experience'], lens),\n",
    "                    'skills': chainer(fa['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = fa.loc[fa.skills.str.contains('|'.join(fa_sk))]\n",
    "fa.skills = fa.skills.str.strip()\n",
    "\n",
    "fa.loc[(fa.skills.str.contains('1с|1c'), 'skills')] = '1с (предприятие, бухгалтерия)'\n",
    "fa.loc[(fa.skills.str.contains('excel'), 'skills')] = 'excel'\n",
    "fa.loc[(fa.skills.str.contains('powerpoint|презент'), 'skills')] = 'powerpoint'\n",
    "fa.loc[(fa.skills.str.contains('анали'), 'skills')] = 'анализ (данных, финансовый, т.д.)'\n",
    "fa.loc[(fa.skills.str.contains('управление'), 'skills')] = 'управление (рисками, затратами, т.д.)'\n",
    "fa.loc[(fa.skills.str.contains('планирование'), 'skills')] = 'планирование (финансовое, инвестиционное, т.д.)'\n",
    "fa.loc[(fa.skills.str.contains('моделирование'), 'skills')] = 'моделирование (финансовое, экономическое, т.д.)'\n",
    "fa.loc[(fa.skills.str.contains('бухгал'), 'skills')] = 'бухучёт'\n",
    "fa.loc[(fa.skills.str.contains('статистика'), 'skills')] = 'статистика'\n",
    "fa.loc[(fa.skills.str.contains('визуализация'), 'skills')] = 'визуализация'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 / 12 1С-аналитик, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "ac.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = ac.skills.str.split(',').map(len)\n",
    "\n",
    "ac = pd.DataFrame({'id': np.repeat(ac['id'], lens),\n",
    "                    'spec': np.repeat(ac['spec'], lens),\n",
    "                    'experience': np.repeat(ac['experience'], lens),\n",
    "                    'skills': chainer(ac['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = ac.loc[ac.skills.str.contains('|'.join(ac_sk))]\n",
    "ac.skills = ac.skills.str.strip()\n",
    "\n",
    "ac.loc[(ac.skills.str.contains('1с|1c'), 'skills')] = '1с (предприятие, бухгалтерия)'\n",
    "ac.loc[(ac.skills.str.contains('отчетность'), 'skills')] = 'отчетность (налоговая, бухгалтерская)'\n",
    "ac.loc[(ac.skills.str.contains('powerpoint'), 'skills')] = 'powerpoint'\n",
    "ac.loc[(ac.skills.str.contains('документ'), 'skills')] = 'проектная документация'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11 / 12 Продуктовый аналитик, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "pa.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = pa.skills.str.split(',').map(len)\n",
    "\n",
    "pa = pd.DataFrame({'id': np.repeat(pa['id'], lens),\n",
    "                    'spec': np.repeat(pa['spec'], lens),\n",
    "                    'experience': np.repeat(pa['experience'], lens),\n",
    "                    'skills': chainer(pa['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = pa.loc[pa.skills.str.contains('|'.join(pa_sk))]\n",
    "pa.skills = pa.skills.str.strip()\n",
    "\n",
    "pa.loc[(pa.skills.str.contains('sql'), 'skills')] = 'sql'\n",
    "pa.loc[(pa.skills.str.contains('анализ|analys'), 'skills')] = 'анализ (данных, финансовый, т.д.)'\n",
    "pa.loc[(pa.skills.str.contains('bi'), 'skills')] = 'power bi'\n",
    "pa.loc[(pa.skills.str.contains('исследов'), 'skills')] = 'проведение исследований'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12 / 12 Бизнес-аналитик, подготовка к конкату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba.drop(['job_title', 'city', 'employer', 'schedule',\n",
    "         'published', 'salary_from', 'salary_to', 'currency'], \n",
    "         axis=1, inplace=True)\n",
    "ba.skills.replace(NaN, '-', inplace=True)\n",
    "\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split(',')))\n",
    "\n",
    "lens = ba.skills.str.split(',').map(len)\n",
    "\n",
    "ba = pd.DataFrame({'id': np.repeat(ba['id'], lens),\n",
    "                    'spec': np.repeat(ba['spec'], lens),\n",
    "                    'experience': np.repeat(ba['experience'], lens),\n",
    "                    'skills': chainer(ba['skills'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = ba.loc[ba.skills.str.contains('|'.join(ba_sk))]\n",
    "ba.skills = ba.skills.str.strip()\n",
    "\n",
    "ba.loc[(ba.skills.str.contains('анализ'), 'skills')] = 'анализ (данных, финансовый, т.д.)'\n",
    "ba.loc[(ba.skills.str.contains('моделирование'), 'skills')] = 'моделирование (финансовое, экономическое, т.д.)'\n",
    "ba.loc[(ba.skills.str.contains('отчет'), 'skills')] = 'отчетность (налоговая, бухгалтерская)'\n",
    "ba.loc[(ba.skills.str.contains('bi'), 'skills')] = 'bi-системы'\n",
    "ba.loc[(ba.skills.str.contains('документ'), 'skills')] = 'проектная документация'\n",
    "ba.loc[(ba.skills.str.contains('оптимизация'), 'skills')] = 'оптимизация процессов'\n",
    "ba.loc[(ba.skills.str.contains('исследов'), 'skills')] = 'проведение исследований'\n",
    "ba.loc[(ba.skills.str.contains('тз'), 'skills')] = 'составление тз'\n",
    "ba.loc[(ba.skills.str.contains('сбор'), 'skills')] = 'сбор требований'\n",
    "ba.loc[(ba.skills.str.contains('agile'), 'skills')] = 'agile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ds, do, ab, ad, dj, de, ma, sa, ac, fa, ba, pa])\n",
    "df.skills.replace(NaN, '-', inplace=True)\n",
    "df.to_excel('key_skills.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сводная статистика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = pd.read_excel('results/agg_stat.xlsx', sheet_name='count_of_vac')\n",
    "dist = pd.read_excel('results/agg_stat.xlsx', sheet_name='exp_distribution')\n",
    "m_sal = pd.read_excel('results/agg_stat.xlsx', sheet_name='median_sal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "p = Path(r'C:\\Users\\ePROkhorov\\Documents\\hh_API_new\\results\\raw').glob('**/*')\n",
    "files = [x for x in p]\n",
    "\n",
    "# добавить кол-во новых вакансий замесяц\n",
    "for file in files:\n",
    "    months = ['янв', 'фев', 'мар', 'апр', 'май', 'июн', 'июл', 'авг', 'сен', 'окт', 'ноя', 'дек']\n",
    "    month = ''\n",
    "    year = datetime.now().year\n",
    "    name = file.stem\n",
    "    df = pd.read_csv(file, sep=';', encoding='utf-8')\n",
    "    for i, el in enumerate(months):\n",
    "        if datetime.now().month == i + 2:\n",
    "            month = el\n",
    "    row = {'spec': name, 'year': year, 'month': month, 'count': len(df)}\n",
    "    count = pd.concat([count, pd.DataFrame([row])])\n",
    "\n",
    "# апдейтнуть распределение вакансий за год\n",
    "for file in files:\n",
    "    year = datetime.now().year\n",
    "    name = file.stem  \n",
    "    df = pd.read_csv(file, sep=';', encoding='utf-8')\n",
    "    exp_new = (df.experience.value_counts()\n",
    "               .to_frame()\n",
    "               .reset_index()\n",
    "               .rename({'experience': 'exp', 'count': 'distrib'}, axis=1))\n",
    "    exp_old = dist.loc[(dist.spec == name) & (dist.year == year)][['exp', 'distrib']].reset_index(drop=True)\n",
    "    merged_df = pd.merge(exp_old, exp_new, on=[\"exp\"], how='outer', suffixes=(\"_test\", \"_new\")).replace(np.nan, 0)\n",
    "    merged_df[\"distrib\"] = merged_df[\"distrib_test\"] + merged_df[\"distrib_new\"]\n",
    "    merged_df.drop(['distrib_test', 'distrib_new'], axis=1, inplace=True)\n",
    "    res = merged_df.distrib.astype(int).to_list()\n",
    "    dist.loc[(dist.spec == name) & (dist.year == year), 'distrib'] = res\n",
    "            \n",
    "# апдейтнуть медианные зп за год\n",
    "for file in files:\n",
    "    year = datetime.now().year\n",
    "    name = file.stem  \n",
    "    df = pd.read_csv(file, sep=';', encoding='utf-8')  \n",
    "    sal_new = np.array([df.salary_from.median(), df.salary_to.median()]).mean()\n",
    "    ind = m_sal.loc[(m_sal.spec == name) & (m_sal.year == datetime.now().year)].index\n",
    "    sal_old = m_sal.iloc[ind]['sal'].reset_index().sal.values[0]\n",
    "    m_sal.loc[(m_sal.spec == name) & (m_sal.year == datetime.now().year), 'sal'] = np.array([sal_old, sal_new]).mean()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f381cf5d24b160f072f225185fee60e069c3036297c4cd5004a026eb9033355a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
